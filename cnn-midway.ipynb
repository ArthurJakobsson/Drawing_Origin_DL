{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "124b7e92-66f1-4417-86aa-94accecc96d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import ndjson\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf05f794",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'strawberry.ndjson'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/arthurjakobsson/Documents/10617/Project/cnn-midway.ipynb Cell 2\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arthurjakobsson/Documents/10617/Project/cnn-midway.ipynb#X11sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m             sample \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform(sample)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arthurjakobsson/Documents/10617/Project/cnn-midway.ipynb#X11sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m sample\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/arthurjakobsson/Documents/10617/Project/cnn-midway.ipynb#X11sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m dataloader \u001b[39m=\u001b[39m ImageDataLoader(\u001b[39m100\u001b[39;49m)\n",
      "\u001b[1;32m/Users/arthurjakobsson/Documents/10617/Project/cnn-midway.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arthurjakobsson/Documents/10617/Project/cnn-midway.ipynb#X11sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m img_list \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mlistdir(img_path)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arthurjakobsson/Documents/10617/Project/cnn-midway.ipynb#X11sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m data_list \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mlistdir(data_dir)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/arthurjakobsson/Documents/10617/Project/cnn-midway.ipynb#X11sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimg_npy \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([np\u001b[39m.\u001b[39mload(fname) \u001b[39mfor\u001b[39;00m fname \u001b[39min\u001b[39;00m img_list])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arthurjakobsson/Documents/10617/Project/cnn-midway.ipynb#X11sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mprint\u001b[39m(img_npy\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arthurjakobsson/Documents/10617/Project/cnn-midway.ipynb#X11sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_dir \u001b[39m=\u001b[39m data_list\n",
      "\u001b[1;32m/Users/arthurjakobsson/Documents/10617/Project/cnn-midway.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arthurjakobsson/Documents/10617/Project/cnn-midway.ipynb#X11sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m img_list \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mlistdir(img_path)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arthurjakobsson/Documents/10617/Project/cnn-midway.ipynb#X11sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m data_list \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mlistdir(data_dir)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/arthurjakobsson/Documents/10617/Project/cnn-midway.ipynb#X11sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimg_npy \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([np\u001b[39m.\u001b[39;49mload(fname) \u001b[39mfor\u001b[39;00m fname \u001b[39min\u001b[39;00m img_list])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arthurjakobsson/Documents/10617/Project/cnn-midway.ipynb#X11sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mprint\u001b[39m(img_npy\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arthurjakobsson/Documents/10617/Project/cnn-midway.ipynb#X11sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_dir \u001b[39m=\u001b[39m data_list\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/numpy/lib/npyio.py:427\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    425\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 427\u001b[0m     fid \u001b[39m=\u001b[39m stack\u001b[39m.\u001b[39menter_context(\u001b[39mopen\u001b[39;49m(os_fspath(file), \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m    428\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[39m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'strawberry.ndjson'"
     ]
    }
   ],
   "source": [
    "class ImageDataLoader(Dataset):\n",
    "    \"\"\"Quick Draw and Image dataset.\"\"\"\n",
    "\n",
    "    def parseSimplifiedDrawings(fileName):\n",
    "        drawings = []\n",
    "        with open(fileName, 'r') as fileStream:\n",
    "            for obj in ndjson.load(fileStream):\n",
    "                drawings.append(obj)\n",
    "        return drawings\n",
    "\n",
    "    def __init__(self, len, img_dir=\"data\", data_dir=\"images\"):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            img_dir (string): path to images\n",
    "            data_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.len = len\n",
    "        self.absolute_path = \"/Users/arthurjakobsson/Documents/10617/Project/\"\n",
    "        img_path = os.path.join(self.absolute_path, img_dir)\n",
    "        data_path = os.path.join(self.absolute_path, data_dir)\n",
    "        img_list = os.listdir(img_path)\n",
    "        data_list = os.listdir(data_dir)\n",
    "        self.img_npy = np.array([np.load(fname) for fname in img_list])\n",
    "        print(img_npy.shape)\n",
    "        self.data_dir = data_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        drawings = parseSimplifiedDrawings(\"data/fence.ndjson\")\n",
    "        #for d in drawings:\n",
    "            #print(d['key_id'], d['countrycode'])\n",
    "        print(\"# of drawings:\", len(drawings))\n",
    "\n",
    "        # img_name = os.path.join(self.root_dir,\n",
    "        #                         self.landmarks_frame.iloc[idx, 0])\n",
    "        # image = io.imread(img_name)\n",
    "        # landmarks = self.landmarks_frame.iloc[idx, 1:]\n",
    "        # landmarks = np.array([landmarks], dtype=float).reshape(-1, 2)\n",
    "        # sample = {'image': image, 'landmarks': landmarks}\n",
    "\n",
    "        # if self.transform:\n",
    "        #     sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "\n",
    "dataloader = ImageDataLoader(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b56c09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe96a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "batch_size = 32\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "class OurCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=(3,3), stride=1, padding=1)\n",
    "        self.act1 = nn.LogSoftmax(dim=1)\n",
    "        self.drop1 = nn.Dropout(0.3)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=(3,3), stride=1, padding=1)\n",
    "        self.act2 = nn.LogSoftmax(dim=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "\n",
    "        self.flat = nn.Flatten()\n",
    "\n",
    "        self.fc3 = nn.Linear(8192, 512)\n",
    "        self.act3 = nn.LogSoftmax(dim=1)\n",
    "        self.drop3 = nn.Dropout(0.5)\n",
    "\n",
    "        self.fc4 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input 3x32x32, output 32x32x32\n",
    "        x = self.act1(self.conv1(x))\n",
    "        x = self.drop1(x)\n",
    "        # input 32x32x32, output 32x32x32\n",
    "        x = self.act2(self.conv2(x))\n",
    "        # input 32x32x32, output 32x16x16\n",
    "        x = self.pool2(x)\n",
    "        # input 32x16x16, output 8192\n",
    "        x = self.flat(x)\n",
    "        # input 8192, output 512\n",
    "        x = self.act3(self.fc3(x))\n",
    "        x = self.drop3(x)\n",
    "        # input 512, output 10\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "model = OurCNN()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "n_epochs = 20\n",
    "for epoch in range(n_epochs):\n",
    "    for inputs, labels in trainloader:\n",
    "        # forward, backward, and then weight update\n",
    "        y_pred = model(inputs)\n",
    "        loss = loss_fn(y_pred, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    acc = 0\n",
    "    count = 0\n",
    "    for inputs, labels in testloader:\n",
    "        y_pred = model(inputs)\n",
    "        acc += (torch.argmax(y_pred, 1) == labels).float().sum()\n",
    "        count += len(labels)\n",
    "    acc /= count\n",
    "    print(\"Epoch %d: model accuracy %.2f%%\" % (epoch, acc*100))\n",
    "\n",
    "torch.save(model.state_dict(), \"cifar10model.pth\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
