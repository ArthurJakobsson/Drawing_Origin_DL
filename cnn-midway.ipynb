{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "124b7e92-66f1-4417-86aa-94accecc96d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import ndjson\n",
    "import os\n",
    "import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "IMAGESIZE = 28\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseSimplifiedDrawings(fileName, num):\n",
    "        drawings = []\n",
    "        with open(fileName, 'r') as fileStream:\n",
    "            json_list = ndjson.load(fileStream)\n",
    "            idx_range = min(num, len(json_list))\n",
    "            for obj in range(idx_range):\n",
    "                drawings.append(json_list[obj])\n",
    "        return drawings\n",
    "\n",
    "def prepare_datafiles(length, per_class, img_dir=\"images\", data_dir=\"data\"):\n",
    "        absolute_path = \"/Users/arthurjakobsson/Documents/10617/Project/\"\n",
    "        img_path = os.path.join(absolute_path, img_dir)\n",
    "        data_path = os.path.join(absolute_path, data_dir)\n",
    "        # img_list = sorted(os.listdir(img_path))\n",
    "        # data_list = sorted(os.listdir(data_dir))\n",
    "        data_list = [\"apple.ndjson\", \"ant.ndjson\", \"car.ndjson\", \"book.ndjson\", \"leaf.ndjson\", \"hourglass.ndjson\", \"rabbit.ndjson\", \"truck.ndjson\", \"skyscraper.ndjson\", \"umbrella.ndjson\"]\n",
    "        img_list = [\"apple.npy\", \"ant.npy\", \"car.npy\", \"book.npy\", \"leaf.npy\", \"hourglass.npy\", \"rabbit.npy\", \"truck.npy\", \"skyscraper.npy\", \"umbrella.npy\"]\n",
    "        # img_list = img_list[0:length] # cut classes it short\n",
    "        # data_list = data_list[0:length] # cut it classes short\n",
    "\n",
    "        print(img_list)\n",
    "        print(data_list)\n",
    "        img_npy = np.vstack([np.load(os.path.join(img_path, fname))[0:per_class] for fname in img_list])\n",
    "        print(img_npy.shape)\n",
    "        allDrawings = []\n",
    "        for fname in data_list:\n",
    "            drawings = parseSimplifiedDrawings(\"data/\"+ fname, per_class)\n",
    "            allDrawings += drawings\n",
    "            print(fname)\n",
    "        dicts = np.array([allDrawings]).T\n",
    "\n",
    "        img_npy = np.array(img_npy)\n",
    "        data_dir = data_list\n",
    "\n",
    "        finalData = np.hstack([img_npy, dicts])\n",
    "        print(finalData.shape)\n",
    "        length = finalData.shape[0]\n",
    "        np.save(\"AllData.npy\", finalData)\n",
    "\n",
    "# prepare_datafiles(0, per_class=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataLoader(Dataset):\n",
    "    \"\"\"Quick Draw and Image dataset.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            len: length of data requested\n",
    "            img_dir (string): path to images\n",
    "            data_dir (string): Directory with all the images.\n",
    "        \"\"\"\n",
    "        self.data = np.load(\"AllData.npy\", allow_pickle=True)\n",
    "        self.length = self.data.shape[0]\n",
    "        self.outputSize, self.countryDict = self.getUniqueCountryCount()\n",
    "\n",
    "        self.xData = self.data[:,:(IMAGESIZE*IMAGESIZE)]\n",
    "        dataInfo = self.data[:, IMAGESIZE*IMAGESIZE]\n",
    "        print(dataInfo.shape)\n",
    "        #countryCode = np.array([i[\"countrycode\"] for i in dataInfo])\n",
    "        self.category = np.array([i[\"word\"] for i in dataInfo])\n",
    "        # print(self.countryDict)\n",
    "        self.classes = {\n",
    "            \"apple\" : 0,\n",
    "            \"ant\": 1,\n",
    "            \"car\" : 2,\n",
    "            \"book\" : 3,\n",
    "            \"leaf\" : 4,\n",
    "            \"hourglass\" : 5,\n",
    "            \"rabbit\" : 6,\n",
    "            \"truck\" : 7,\n",
    "            \"skyscraper\" : 8,\n",
    "            \"umbrella\" : 9\n",
    "        }\n",
    "        self.xData = self.data[:, :784]\n",
    "        tempyData = self.data[:, 784]\n",
    "        # print(tempyData)\n",
    "        self.yData = []\n",
    "        for val in tempyData:\n",
    "            self.yData.append(self.classes[val[\"word\"]])\n",
    "        self.yData = np.array(self.yData)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx >= self.__len__():\n",
    "            print(\"Index too large for {}-sample dataset\".format(self.__len__()))\n",
    "            return\n",
    "\n",
    "        dataPoint = self.data[idx]\n",
    "\n",
    "        return xData, self.category\n",
    "\n",
    "    def getUniqueCountryCount(self):\n",
    "        d = {}\n",
    "        for elem in self.data:\n",
    "            code = elem[-1][\"countrycode\"]\n",
    "            if code in d:\n",
    "                d[code] +=1\n",
    "            else:\n",
    "                d[code] = 1\n",
    "        return len(d), d\n",
    "\n",
    "    def getData(self):\n",
    "        return self.xData, self.yData\n",
    "\n",
    "    def getCountryInfo(self):\n",
    "        return self.countryDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eda(func):\n",
    "  countryD = func()\n",
    "  fig, ax = plt.subplots(figsize=(18,4))\n",
    "  ax.bar(range(len(countryD)), list(countryD.values()), align='center')\n",
    "  plt.xticks(range(len(countryD)), list(countryD.keys()), rotation = 45)\n",
    "  plt.show()\n",
    "\n",
    "# dataloader = ImageDataLoader()\n",
    "# eda(dataloader.getCountryInfo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dbe96a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000,)\n",
      "lenx 100000\n",
      "leny 100000\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "epoch 0 training done\n",
      "tensor([0, 0, 0,  ..., 9, 9, 9])\n",
      "0\n",
      "here\n",
      "tensor([[[[  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,   0.,   0.,   0.,   0.],\n",
      "          [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,   0.,  11.,  21.,  12.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,   0.,  92.,  20.,   0.],\n",
      "          [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,  91., 213., 253., 255., 255., 222.,  95.,   3.,   0.,   0.,\n",
      "             0.,   0.,   7., 255., 222.,   0.],\n",
      "          [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  24.,\n",
      "           190., 255., 196., 118., 100., 109., 196., 255., 121.,   0.,   0.,\n",
      "             0.,   0.,   0., 141.,  35.,   0.],\n",
      "          [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   1., 185.,\n",
      "           241.,  94.,   1.,   0.,   0.,   0.,   0.,  63.,  25.,   0.,   0.,\n",
      "             0.,   0.,   0.,   0.,   0.,   0.],\n",
      "          [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  89., 255.,\n",
      "           115., 133., 150.,  37.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,   0.,   0.,   0.,   0.],\n",
      "          [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 207., 241.,\n",
      "           252., 255., 250., 199.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,   0.,   0.,   0.,   0.],\n",
      "          [  0.,   0.,   0.,   0.,   0.,   0.,   0.,  30., 200., 255., 242.,\n",
      "           149., 252., 232., 195.,   3.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,   0.,   0.,   0.,   0.],\n",
      "          [  0.,   0.,   0.,   0.,   0.,   0.,  39., 225., 238., 255.,  85.,\n",
      "             0., 119., 255.,  83.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,   0.,   0.,   0.,   0.],\n",
      "          [  0.,   0.,   0.,   0.,   0.,  43., 229., 231., 106., 255.,  49.,\n",
      "             0.,   1., 201., 222.,   7.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,   0.,   0.,   0.,   0.],\n",
      "          [  0.,   0.,   0.,   0.,  33., 237., 220.,  33.,  79., 255.,  75.,\n",
      "             0.,   0.,  61., 255.,  94.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,   0.,   0.,   0.,   0.],\n",
      "          [  0.,   0.,   0.,   4., 197., 235.,  28.,   0.,   4., 210., 166.,\n",
      "             0.,   0.,   1., 250., 127.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,   0.,   0.,   0.,   0.],\n",
      "          [  0.,   0.,   0., 128., 255.,  85.,   0.,   0.,   0.,  17.,  16.,\n",
      "             0.,   0.,   0., 231., 146.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,   0.,   0.,   0.,   0.],\n",
      "          [  0.,   0.,  56., 251., 153.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,   0., 228., 148.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,   0.,   0.,   0.,   0.],\n",
      "          [  0.,   0., 162., 229.,  11.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,   0., 246., 131.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,   0.,   0.,   0.,   0.],\n",
      "          [  0.,   0., 219., 165.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,  13., 255., 111.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,   0.,   0.,   0.,   0.],\n",
      "          [  0.,  21., 254., 109.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,  78., 255.,  58.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,   0.,   0.,   0.,   0.],\n",
      "          [  0.,  78., 255.,  51.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0., 152., 237.,   3.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,   0.,   0.,   0.,   0.],\n",
      "          [  0., 120., 254.,   5.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   3., 228., 165.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,   0.,   0.,   0.,   0.],\n",
      "          [  0., 123., 254.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,  72., 255.,  74.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,   0.,   0.,   0.,   0.],\n",
      "          [  0., 114., 255.,  13.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0., 169., 229.,   3.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,   0.,   0.,   0.,   0.],\n",
      "          [  0.,  60., 255.,  70.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            53., 252., 129.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,   0.,   0.,   0.,   0.],\n",
      "          [  0.,   7., 239., 174.,   0.,   0.,   0.,   0.,   0.,   0.,   6.,\n",
      "           208., 222.,  11.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,   0.,   0.,   0.,   0.],\n",
      "          [  0.,   0., 110., 255., 100.,   0.,   0.,   0.,   0.,   3., 170.,\n",
      "           253.,  70.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,   0.,   0.,   0.,   0.],\n",
      "          [  0.,   0.,   3., 180., 255., 178.,  99.,  68.,  91., 200., 254.,\n",
      "           104.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,   0.,   0.,   0.,   0.],\n",
      "          [  0.,   0.,   0.,   2., 116., 222., 255., 255., 255., 213.,  87.,\n",
      "             0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,   0.,   0.,   0.,   0.],\n",
      "          [  0.,   0.,   0.,   0.,   0.,   0.,  32.,  51.,  44.,   1.,   0.,\n",
      "             0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,   0.,   0.,   0.,   0.],\n",
      "          [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,   0.,   0.,   0.,   0.]]]])\n",
      "tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor([0])\n",
      "Epoch 0: model accuracy 100.00%\n",
      "lenx 100000\n",
      "leny 100000\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "epoch 1 training done\n",
      "tensor([0, 0, 0,  ..., 9, 9, 9])\n",
      "0\n",
      "here\n",
      "tensor([[[[  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,   0.,   0.,   0.,   0.],\n",
      "          [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,   0.,  11.,  21.,  12.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,   0.,  92.,  20.,   0.],\n",
      "          [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,  91., 213., 253., 255., 255., 222.,  95.,   3.,   0.,   0.,\n",
      "             0.,   0.,   7., 255., 222.,   0.],\n",
      "          [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  24.,\n",
      "           190., 255., 196., 118., 100., 109., 196., 255., 121.,   0.,   0.,\n",
      "             0.,   0.,   0., 141.,  35.,   0.],\n",
      "          [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   1., 185.,\n",
      "           241.,  94.,   1.,   0.,   0.,   0.,   0.,  63.,  25.,   0.,   0.,\n",
      "             0.,   0.,   0.,   0.,   0.,   0.],\n",
      "          [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  89., 255.,\n",
      "           115., 133., 150.,  37.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,   0.,   0.,   0.,   0.],\n",
      "          [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 207., 241.,\n",
      "           252., 255., 250., 199.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,   0.,   0.,   0.,   0.],\n",
      "          [  0.,   0.,   0.,   0.,   0.,   0.,   0.,  30., 200., 255., 242.,\n",
      "           149., 252., 232., 195.,   3.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,   0.,   0.,   0.,   0.],\n",
      "          [  0.,   0.,   0.,   0.,   0.,   0.,  39., 225., 238., 255.,  85.,\n",
      "             0., 119., 255.,  83.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,   0.,   0.,   0.,   0.],\n",
      "          [  0.,   0.,   0.,   0.,   0.,  43., 229., 231., 106., 255.,  49.,\n",
      "             0.,   1., 201., 222.,   7.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,   0.,   0.,   0.,   0.],\n",
      "          [  0.,   0.,   0.,   0.,  33., 237., 220.,  33.,  79., 255.,  75.,\n",
      "             0.,   0.,  61., 255.,  94.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,   0.,   0.,   0.,   0.],\n",
      "          [  0.,   0.,   0.,   4., 197., 235.,  28.,   0.,   4., 210., 166.,\n",
      "             0.,   0.,   1., 250., 127.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,   0.,   0.,   0.,   0.],\n",
      "          [  0.,   0.,   0., 128., 255.,  85.,   0.,   0.,   0.,  17.,  16.,\n",
      "             0.,   0.,   0., 231., 146.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,   0.,   0.,   0.,   0.],\n",
      "          [  0.,   0.,  56., 251., 153.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,   0., 228., 148.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,   0.,   0.,   0.,   0.],\n",
      "          [  0.,   0., 162., 229.,  11.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,   0., 246., 131.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,   0.,   0.,   0.,   0.],\n",
      "          [  0.,   0., 219., 165.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,  13., 255., 111.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,   0.,   0.,   0.,   0.],\n",
      "          [  0.,  21., 254., 109.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,  78., 255.,  58.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,   0.,   0.,   0.,   0.],\n",
      "          [  0.,  78., 255.,  51.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0., 152., 237.,   3.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,   0.,   0.,   0.,   0.],\n",
      "          [  0., 120., 254.,   5.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   3., 228., 165.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,   0.,   0.,   0.,   0.],\n",
      "          [  0., 123., 254.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,  72., 255.,  74.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,   0.,   0.,   0.,   0.],\n",
      "          [  0., 114., 255.,  13.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0., 169., 229.,   3.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,   0.,   0.,   0.,   0.],\n",
      "          [  0.,  60., 255.,  70.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            53., 252., 129.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,   0.,   0.,   0.,   0.],\n",
      "          [  0.,   7., 239., 174.,   0.,   0.,   0.,   0.,   0.,   0.,   6.,\n",
      "           208., 222.,  11.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,   0.,   0.,   0.,   0.],\n",
      "          [  0.,   0., 110., 255., 100.,   0.,   0.,   0.,   0.,   3., 170.,\n",
      "           253.,  70.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,   0.,   0.,   0.,   0.],\n",
      "          [  0.,   0.,   3., 180., 255., 178.,  99.,  68.,  91., 200., 254.,\n",
      "           104.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,   0.,   0.,   0.,   0.],\n",
      "          [  0.,   0.,   0.,   2., 116., 222., 255., 255., 255., 213.,  87.,\n",
      "             0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,   0.,   0.,   0.,   0.],\n",
      "          [  0.,   0.,   0.,   0.,   0.,   0.,  32.,  51.,  44.,   1.,   0.,\n",
      "             0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,   0.,   0.,   0.,   0.],\n",
      "          [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.,   0.,   0.,   0.,   0.,   0.]]]])\n",
      "tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor([0])\n",
      "Epoch 1: model accuracy 100.00%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class OurCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=(3,3), stride=1, padding=1)\n",
    "        self.act1 = nn.LogSoftmax(dim=1)\n",
    "        self.drop1 = nn.Dropout(0.3)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=(3,3), stride=1, padding=1)\n",
    "        self.act2 = nn.LogSoftmax(dim=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "\n",
    "        self.flat = nn.Flatten()\n",
    "\n",
    "        self.fc3 = nn.Linear(6272, 512)\n",
    "        self.act3 = nn.LogSoftmax(dim=1)\n",
    "        self.drop3 = nn.Dropout(0.5)\n",
    "\n",
    "        self.fc4 = nn.Linear(512, 10) # add number of unique countries from model\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input 3x32x32, output 32x32x32\n",
    "        x = self.act1(self.conv1(x))\n",
    "        x = self.drop1(x)\n",
    "        # input 32x32x32, output 32x32x32\n",
    "        x = self.act2(self.conv2(x))\n",
    "        # input 32x32x32, output 32x16x16\n",
    "        x = self.pool2(x)\n",
    "        # input 32x16x16, output 8192\n",
    "        x = self.flat(x)\n",
    "        # input 8192, output 512\n",
    "        x = self.act3(self.fc3(x))\n",
    "        x = self.drop3(x)\n",
    "        # input 512, output 10\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "# transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "\n",
    "# trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "# testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# batch_size = 32\n",
    "# trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "# testloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "class trainLoop:\n",
    "    def __init__(self, train_data_loader, eval_data_loader,\n",
    "                        my_model, loss_function,\n",
    "                        outputFolder, batch_size):\n",
    "        # Note: We can access dataset from dataloader by doing dataloader.dataset\n",
    "        self.train_data_loader = train_data_loader\n",
    "        self.eval_data_loader = eval_data_loader\n",
    "        self.my_model = my_model\n",
    "\n",
    "        self.loss_function = loss_function\n",
    "        self.outputFolder = outputFolder\n",
    "        self.batch_size = batch_size\n",
    "        self.optimizer = optim.SGD(self.my_model.parameters(), lr=1e-3)\n",
    "\n",
    "    def shuffleData(self, X, y, epoch):\n",
    "        \"\"\"\n",
    "        DO NOT modify this function.\n",
    "\n",
    "        Permute the training data for SGD.\n",
    "        :param X: The original input data in the order of the file.\n",
    "        :param y: The original labels in the order of the file.\n",
    "        :param epoch: The epoch number (0-indexed).\n",
    "        :return: Permuted X and y training data for the epoch.\n",
    "        \"\"\"\n",
    "        np.random.seed(epoch)\n",
    "        N = len(y)\n",
    "        print(\"lenx\", len(X))\n",
    "        print(\"leny\", len(y))\n",
    "        ordering = np.random.permutation(N)\n",
    "        return X[ordering], y[ordering]\n",
    "\n",
    "\n",
    "\n",
    "    def runEpoch(self, epoch):\n",
    "        xDataStart, yDataStart = self.train_data_loader.getData()\n",
    "        xData, yData = self.shuffleData(xDataStart, yDataStart, epoch)\n",
    "        xData, yData = xData.astype('f'), yData.astype('l')\n",
    "        xData = torch.from_numpy(xData.reshape(-1,28,28))\n",
    "        yData = torch.from_numpy(yData)\n",
    "\n",
    "        batchSize = self.batch_size\n",
    "        for i in range(len(xData) // batchSize):\n",
    "            if i % 10 == 0:\n",
    "                print(i)\n",
    "            if i == 50:\n",
    "                break\n",
    "            batchX = xData[i*batchSize:i*batchSize + batchSize]\n",
    "            batchY = yData[i*batchSize:i*batchSize + batchSize]\n",
    "            batchX = np.reshape(batchX, (batchX.shape[0],1, batchX.shape[1], batchX.shape[2]))\n",
    "            y_pred = self.my_model(batchX)\n",
    "            loss = self.loss_function(y_pred, batchY)\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "    def runModel(self, epochCount):\n",
    "        for i in range(epochCount):\n",
    "            self.runEpoch(i)\n",
    "            print(\"epoch \" + str(i) + \" training done\")\n",
    "            acc = 0\n",
    "            count = 0\n",
    "            batchSize = 1\n",
    "            xData, yData = self.train_data_loader.getData()\n",
    "            xData, yData = xData.astype('f'), yData.astype('l')\n",
    "            xData = torch.from_numpy(xData.reshape(-1,28,28))\n",
    "            yData = torch.from_numpy(yData)\n",
    "            print(yData)\n",
    "            for j in range(len(xData) // batchSize):\n",
    "                if j % 5 == 0:\n",
    "                    print(j)\n",
    "                if j == 1:\n",
    "                    break\n",
    "                batchX = xData[j*batchSize:j*batchSize + batchSize]\n",
    "                batchY = yData[j*batchSize:j*batchSize + batchSize]\n",
    "                batchX = np.reshape(batchX, (batchX.shape[0],1, batchX.shape[1], batchX.shape[2]))\n",
    "                print(\"here\")\n",
    "                print(batchX)\n",
    "                y_pred = self.my_model(batchX)\n",
    "                print(y_pred)\n",
    "                print(batchY)\n",
    "                acc += (torch.argmax(y_pred, 1) == batchY).float().sum()\n",
    "                count += len(batchY)\n",
    "            acc /= count\n",
    "            print(\"Epoch %d: model accuracy %.2f%%\" % (i, acc*100))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = OurCNN()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "TrainDataLoader = ImageDataLoader()\n",
    "# TestDataLoader = ImageDataLoader()\n",
    "training = trainLoop(TrainDataLoader, TrainDataLoader, model, loss_fn, \"models\", 100)\n",
    "training.runModel(2)\n",
    "torch.save(model.state_dict(), \"models/categoryModel1.pth\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
