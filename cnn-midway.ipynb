{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "124b7e92-66f1-4417-86aa-94accecc96d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import ndjson\n",
    "import os\n",
    "import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "IMAGESIZE = 28\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseSimplifiedDrawings(fileName, num):\n",
    "        drawings = []\n",
    "        with open(fileName, 'r') as fileStream:\n",
    "            json_list = ndjson.load(fileStream)\n",
    "            idx_range = min(num, len(json_list))\n",
    "            for obj in range(idx_range):\n",
    "                drawings.append(json_list[obj])\n",
    "        return drawings\n",
    "\n",
    "def prepare_datafiles(length, per_class, img_dir=\"images\", data_dir=\"data\"):\n",
    "        absolute_path = \"/Users/arthurjakobsson/Documents/10617/Project/\"\n",
    "        img_path = os.path.join(absolute_path, img_dir)\n",
    "        data_path = os.path.join(absolute_path, data_dir)\n",
    "        # img_list = sorted(os.listdir(img_path))\n",
    "        # data_list = sorted(os.listdir(data_dir))\n",
    "        data_list = [\"apple.ndjson\", \"ant.ndjson\", \"car.ndjson\", \"book.ndjson\", \"leaf.ndjson\", \"hourglass.ndjson\", \"rabbit.ndjson\", \"truck.ndjson\", \"skyscraper.ndjson\", \"umbrella.ndjson\"]\n",
    "        img_list = [\"apple.npy\", \"ant.npy\", \"car.npy\", \"book.npy\", \"leaf.npy\", \"hourglass.npy\", \"rabbit.npy\", \"truck.npy\", \"skyscraper.npy\", \"umbrella.npy\"]\n",
    "        # img_list = img_list[0:length] # cut classes it short\n",
    "        # data_list = data_list[0:length] # cut it classes short\n",
    "\n",
    "        print(img_list)\n",
    "        print(data_list)\n",
    "        img_npy = np.vstack([np.load(os.path.join(img_path, fname))[0:per_class] for fname in img_list])\n",
    "        print(img_npy.shape)\n",
    "        allDrawings = []\n",
    "        for fname in data_list:\n",
    "            drawings = parseSimplifiedDrawings(\"data/\"+ fname, per_class)\n",
    "            allDrawings += drawings\n",
    "            print(fname)\n",
    "        dicts = np.array([allDrawings]).T\n",
    "\n",
    "        img_npy = np.array(img_npy)\n",
    "        data_dir = data_list\n",
    "\n",
    "        finalData = np.hstack([img_npy, dicts])\n",
    "        print(finalData.shape)\n",
    "        length = finalData.shape[0]\n",
    "        np.save(\"AllData.npy\", finalData)\n",
    "\n",
    "# prepare_datafiles(0, per_class=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataLoader(Dataset):\n",
    "    \"\"\"Quick Draw and Image dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, train):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            len: length of data requested\n",
    "            img_dir (string): path to images\n",
    "            data_dir (string): Directory with all the images.\n",
    "        \"\"\"\n",
    "        allData = np.load(\"AllData.npy\", allow_pickle=True)\n",
    "        if train:\n",
    "            data = []\n",
    "            for i in range(10):\n",
    "                data.append(allData[i*10000:i*10000+8000,])\n",
    "            self.data = np.vstack(data)\n",
    "        else:\n",
    "            data = []\n",
    "            for i in range(10):\n",
    "                data.append(allData[i*10000+8000:(i+1)*10000,])\n",
    "            self.data = np.vstack(data)\n",
    "\n",
    "\n",
    "        self.length = self.data.shape[0]\n",
    "        self.outputSize, self.countryDict = self.getUniqueCountryCount()\n",
    "\n",
    "        self.xData = self.data[:,:(IMAGESIZE*IMAGESIZE)]\n",
    "        dataInfo = self.data[:, IMAGESIZE*IMAGESIZE]\n",
    "        print(dataInfo.shape)\n",
    "        #countryCode = np.array([i[\"countrycode\"] for i in dataInfo])\n",
    "        self.category = np.array([i[\"word\"] for i in dataInfo])\n",
    "        # print(self.countryDict)\n",
    "        self.classes = {\n",
    "            \"apple\" : 0,\n",
    "            \"ant\": 1,\n",
    "            \"car\" : 2,\n",
    "            \"book\" : 3,\n",
    "            \"leaf\" : 4,\n",
    "            \"hourglass\" : 5,\n",
    "            \"rabbit\" : 6,\n",
    "            \"truck\" : 7,\n",
    "            \"skyscraper\" : 8,\n",
    "            \"umbrella\" : 9\n",
    "        }\n",
    "        self.xData = self.data[:, :784]\n",
    "        tempyData = self.data[:, 784]\n",
    "        # print(tempyData)\n",
    "        self.yData = []\n",
    "        for val in tempyData:\n",
    "            self.yData.append(self.classes[val[\"word\"]])\n",
    "        self.yData = np.array(self.yData)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx >= self.__len__():\n",
    "            print(\"Index too large for {}-sample dataset\".format(self.__len__()))\n",
    "            return\n",
    "\n",
    "        dataPoint = self.data[idx]\n",
    "\n",
    "        return xData, self.category\n",
    "\n",
    "    def getUniqueCountryCount(self):\n",
    "        d = {}\n",
    "        for elem in self.data:\n",
    "            code = elem[-1][\"countrycode\"]\n",
    "            if code in d:\n",
    "                d[code] +=1\n",
    "            else:\n",
    "                d[code] = 1\n",
    "        return len(d), d\n",
    "\n",
    "    def getData(self):\n",
    "        return self.xData, self.yData\n",
    "\n",
    "    def getCountryInfo(self):\n",
    "        return self.countryDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eda(func):\n",
    "  countryD = func()\n",
    "  fig, ax = plt.subplots(figsize=(18,4))\n",
    "  ax.bar(range(len(countryD)), list(countryD.values()), align='center')\n",
    "  plt.xticks(range(len(countryD)), list(countryD.keys()), rotation = 45)\n",
    "  plt.show()\n",
    "\n",
    "# dataloader = ImageDataLoader()\n",
    "# eda(dataloader.getCountryInfo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbe96a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000,)\n",
      "(20000,)\n",
      "lenx 80000\n",
      "leny 80000\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch 0 training done\n",
      "tensor([0, 0, 0,  ..., 9, 9, 9])\n",
      "20000\n",
      "20\n",
      "0\n",
      "10\n",
      "acc  tensor(15906.)\n",
      "count  20000\n",
      "Epoch 0: model accuracy 79.53%\n",
      "lenx 80000\n",
      "leny 80000\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch 1 training done\n",
      "tensor([0, 0, 0,  ..., 9, 9, 9])\n",
      "20000\n",
      "20\n",
      "0\n",
      "10\n",
      "acc  tensor(16701.)\n",
      "count  20000\n",
      "Epoch 1: model accuracy 83.50%\n",
      "lenx 80000\n",
      "leny 80000\n",
      "0\n",
      "100\n",
      "200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[E thread_pool.cpp:110] Exception in thread pool task: mutex lock failed: Invalid argument\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/arthurjakobsson/Documents/10617/Project/cnn-midway.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/arthurjakobsson/Documents/10617/Project/cnn-midway.ipynb#X13sZmlsZQ%3D%3D?line=136'>137</a>\u001b[0m TestDataLoader \u001b[39m=\u001b[39m ImageDataLoader(train\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/arthurjakobsson/Documents/10617/Project/cnn-midway.ipynb#X13sZmlsZQ%3D%3D?line=137'>138</a>\u001b[0m training \u001b[39m=\u001b[39m trainLoop(TrainDataLoader, TestDataLoader, model, loss_fn, \u001b[39m\"\u001b[39m\u001b[39mmodels\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m100\u001b[39m)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/arthurjakobsson/Documents/10617/Project/cnn-midway.ipynb#X13sZmlsZQ%3D%3D?line=138'>139</a>\u001b[0m training\u001b[39m.\u001b[39;49mrunModel(\u001b[39m20\u001b[39;49m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/arthurjakobsson/Documents/10617/Project/cnn-midway.ipynb#X13sZmlsZQ%3D%3D?line=139'>140</a>\u001b[0m torch\u001b[39m.\u001b[39msave(model\u001b[39m.\u001b[39mstate_dict(), \u001b[39m\"\u001b[39m\u001b[39mmodels/categoryModel1.pth\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/Users/arthurjakobsson/Documents/10617/Project/cnn-midway.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/arthurjakobsson/Documents/10617/Project/cnn-midway.ipynb#X13sZmlsZQ%3D%3D?line=100'>101</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrunModel\u001b[39m(\u001b[39mself\u001b[39m, epochCount):\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/arthurjakobsson/Documents/10617/Project/cnn-midway.ipynb#X13sZmlsZQ%3D%3D?line=101'>102</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochCount):\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/arthurjakobsson/Documents/10617/Project/cnn-midway.ipynb#X13sZmlsZQ%3D%3D?line=102'>103</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunEpoch(i)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/arthurjakobsson/Documents/10617/Project/cnn-midway.ipynb#X13sZmlsZQ%3D%3D?line=103'>104</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mepoch \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(i) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m training done\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/arthurjakobsson/Documents/10617/Project/cnn-midway.ipynb#X13sZmlsZQ%3D%3D?line=104'>105</a>\u001b[0m         acc \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "\u001b[1;32m/Users/arthurjakobsson/Documents/10617/Project/cnn-midway.ipynb Cell 5\u001b[0m line \u001b[0;36m9\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arthurjakobsson/Documents/10617/Project/cnn-midway.ipynb#X13sZmlsZQ%3D%3D?line=92'>93</a>\u001b[0m batchY \u001b[39m=\u001b[39m yData[i\u001b[39m*\u001b[39mbatchSize:i\u001b[39m*\u001b[39mbatchSize \u001b[39m+\u001b[39m batchSize]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arthurjakobsson/Documents/10617/Project/cnn-midway.ipynb#X13sZmlsZQ%3D%3D?line=93'>94</a>\u001b[0m batchX \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mreshape(batchX, (batchX\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m],\u001b[39m1\u001b[39m, batchX\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], batchX\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m]))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/arthurjakobsson/Documents/10617/Project/cnn-midway.ipynb#X13sZmlsZQ%3D%3D?line=94'>95</a>\u001b[0m y_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmy_model(batchX)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arthurjakobsson/Documents/10617/Project/cnn-midway.ipynb#X13sZmlsZQ%3D%3D?line=95'>96</a>\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_function(y_pred, batchY)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arthurjakobsson/Documents/10617/Project/cnn-midway.ipynb#X13sZmlsZQ%3D%3D?line=96'>97</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/Users/arthurjakobsson/Documents/10617/Project/cnn-midway.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arthurjakobsson/Documents/10617/Project/cnn-midway.ipynb#X13sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mact2(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(x))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arthurjakobsson/Documents/10617/Project/cnn-midway.ipynb#X13sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m# input 32x32x32, output 32x16x16\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/arthurjakobsson/Documents/10617/Project/cnn-midway.ipynb#X13sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpool2(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arthurjakobsson/Documents/10617/Project/cnn-midway.ipynb#X13sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# input 32x16x16, output 8192\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arthurjakobsson/Documents/10617/Project/cnn-midway.ipynb#X13sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mflat(x)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/pooling.py:166\u001b[0m, in \u001b[0;36mMaxPool2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor):\n\u001b[0;32m--> 166\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mmax_pool2d(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel_size, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    167\u001b[0m                         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, ceil_mode\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mceil_mode,\n\u001b[1;32m    168\u001b[0m                         return_indices\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreturn_indices)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/_jit_internal.py:488\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    486\u001b[0m     \u001b[39mreturn\u001b[39;00m if_true(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    487\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 488\u001b[0m     \u001b[39mreturn\u001b[39;00m if_false(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/functional.py:791\u001b[0m, in \u001b[0;36m_max_pool2d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[39mif\u001b[39;00m stride \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    790\u001b[0m     stride \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mannotate(List[\u001b[39mint\u001b[39m], [])\n\u001b[0;32m--> 791\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mmax_pool2d(\u001b[39minput\u001b[39;49m, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "class OurCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=(3,3), stride=1, padding=1)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.drop1 = nn.Dropout(0.3)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=(3,3), stride=1, padding=1)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "\n",
    "        self.flat = nn.Flatten()\n",
    "\n",
    "        self.fc3 = nn.Linear(6272, 512)\n",
    "        self.act3 = nn.ReLU()\n",
    "        self.drop3 = nn.Dropout(0.5)\n",
    "\n",
    "        self.fc4 = nn.Linear(512, 10) # add number of unique countries from model\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input 3x32x32, output 32x32x32\n",
    "        x = self.act1(self.conv1(x))\n",
    "        x = self.drop1(x)\n",
    "        # input 32x32x32, output 32x32x32\n",
    "        x = self.act2(self.conv2(x))\n",
    "        # input 32x32x32, output 32x16x16\n",
    "        x = self.pool2(x)\n",
    "        # input 32x16x16, output 8192\n",
    "        x = self.flat(x)\n",
    "        # input 8192, output 512\n",
    "        x = self.act3(self.fc3(x))\n",
    "        x = self.drop3(x)\n",
    "        # input 512, output 10\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "# transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "\n",
    "# trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "# testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# batch_size = 32\n",
    "# trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "# testloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "class trainLoop:\n",
    "    def __init__(self, train_data_loader, eval_data_loader,\n",
    "                        my_model, loss_function,\n",
    "                        outputFolder, batch_size):\n",
    "        # Note: We can access dataset from dataloader by doing dataloader.dataset\n",
    "        self.train_data_loader = train_data_loader\n",
    "        self.eval_data_loader = eval_data_loader\n",
    "        self.my_model = my_model\n",
    "\n",
    "        self.loss_function = loss_function\n",
    "        self.outputFolder = outputFolder\n",
    "        self.batch_size = batch_size\n",
    "        self.optimizer = optim.SGD(self.my_model.parameters(), lr=1e-3)\n",
    "\n",
    "    def shuffleData(self, X, y, epoch):\n",
    "        \"\"\"\n",
    "        DO NOT modify this function.\n",
    "\n",
    "        Permute the training data for SGD.\n",
    "        :param X: The original input data in the order of the file.\n",
    "        :param y: The original labels in the order of the file.\n",
    "        :param epoch: The epoch number (0-indexed).\n",
    "        :return: Permuted X and y training data for the epoch.\n",
    "        \"\"\"\n",
    "        np.random.seed(epoch)\n",
    "        N = len(y)\n",
    "        print(\"lenx\", len(X))\n",
    "        print(\"leny\", len(y))\n",
    "        ordering = np.random.permutation(N)\n",
    "        return X[ordering], y[ordering]\n",
    "\n",
    "\n",
    "\n",
    "    def runEpoch(self, epoch):\n",
    "        xDataStart, yDataStart = self.train_data_loader.getData()\n",
    "        xData, yData = self.shuffleData(xDataStart, yDataStart, epoch)\n",
    "        xData, yData = xData.astype('f'), yData.astype('l')\n",
    "        xData = torch.from_numpy(xData.reshape(-1,28,28))\n",
    "        yData = torch.from_numpy(yData)\n",
    "\n",
    "        batchSize = self.batch_size\n",
    "        for i in range(len(xData) // batchSize):\n",
    "            if i % 100 == 0:\n",
    "                print(i)\n",
    "            batchX = xData[i*batchSize:i*batchSize + batchSize]\n",
    "            batchY = yData[i*batchSize:i*batchSize + batchSize]\n",
    "            batchX = np.reshape(batchX, (batchX.shape[0],1, batchX.shape[1], batchX.shape[2]))\n",
    "            y_pred = self.my_model(batchX)\n",
    "            loss = self.loss_function(y_pred, batchY)\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "    def runModel(self, epochCount):\n",
    "        for i in range(epochCount):\n",
    "            self.runEpoch(i)\n",
    "            print(\"epoch \" + str(i) + \" training done\")\n",
    "            acc = 0\n",
    "            count = 0\n",
    "            batchSize = 1000\n",
    "            xData, yData = self.eval_data_loader.getData()\n",
    "            xData, yData = xData.astype('f'), yData.astype('l')\n",
    "            xData = torch.from_numpy(xData.reshape(-1,28,28))\n",
    "            yData = torch.from_numpy(yData)\n",
    "            print(yData)\n",
    "            print(len(xData))\n",
    "            print(len(xData) // batchSize)\n",
    "            for j in range(len(xData) // batchSize):\n",
    "                if j % 10 == 0:\n",
    "                    print(j)\n",
    "                batchX = xData[j*batchSize:j*batchSize + batchSize]\n",
    "                batchY = yData[j*batchSize:j*batchSize + batchSize]\n",
    "                batchX = np.reshape(batchX, (batchX.shape[0],1, batchX.shape[1], batchX.shape[2]))\n",
    "                # print(\"here\")\n",
    "                # print(batchX)\n",
    "                y_pred = self.my_model(batchX)\n",
    "                # print(y_pred)\n",
    "                # print(batchY)\n",
    "                acc += (torch.argmax(y_pred, 1) == batchY).float().sum()\n",
    "                count += len(batchY)\n",
    "            print(\"acc \", acc)\n",
    "            print(\"count \", count)\n",
    "            acc /= count\n",
    "            print(\"Epoch %d: model accuracy %.2f%%\" % (i, acc*100))\n",
    "\n",
    "\n",
    "model = OurCNN()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "TrainDataLoader = ImageDataLoader(train=True)\n",
    "TestDataLoader = ImageDataLoader(train=False)\n",
    "training = trainLoop(TrainDataLoader, TestDataLoader, model, loss_fn, \"models\", 100)\n",
    "training.runModel(20)\n",
    "torch.save(model.state_dict(), \"models/categoryModel1.pth\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
