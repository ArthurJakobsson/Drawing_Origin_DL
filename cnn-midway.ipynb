{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "124b7e92-66f1-4417-86aa-94accecc96d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import ndjson\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf05f794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101017616,) (124285168,)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'img_npy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/arthurjakobsson/Documents/10617/Project/cnn-midway.ipynb Cell 2\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arthurjakobsson/Documents/10617/Project/cnn-midway.ipynb#X11sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m         \u001b[39m# img_name = os.path.join(self.root_dir,\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arthurjakobsson/Documents/10617/Project/cnn-midway.ipynb#X11sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m         \u001b[39m#                         self.landmarks_frame.iloc[idx, 0])\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arthurjakobsson/Documents/10617/Project/cnn-midway.ipynb#X11sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m         \u001b[39m# image = io.imread(img_name)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arthurjakobsson/Documents/10617/Project/cnn-midway.ipynb#X11sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m         \u001b[39m# if self.transform:\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arthurjakobsson/Documents/10617/Project/cnn-midway.ipynb#X11sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m         \u001b[39m#     sample = self.transform(sample)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arthurjakobsson/Documents/10617/Project/cnn-midway.ipynb#X11sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m sample\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/arthurjakobsson/Documents/10617/Project/cnn-midway.ipynb#X11sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m dataloader \u001b[39m=\u001b[39m ImageDataLoader(\u001b[39m100\u001b[39;49m)\n",
      "\u001b[1;32m/Users/arthurjakobsson/Documents/10617/Project/cnn-midway.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arthurjakobsson/Documents/10617/Project/cnn-midway.ipynb#X11sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimg_npy \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39mmoveaxis(np\u001b[39m.\u001b[39mload(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(img_path, fname)),\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mflatten() \u001b[39mfor\u001b[39;00m fname \u001b[39min\u001b[39;00m img_list]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arthurjakobsson/Documents/10617/Project/cnn-midway.ipynb#X11sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimg_npy[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimg_npy[\u001b[39m2\u001b[39m]\u001b[39m.\u001b[39mshape)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/arthurjakobsson/Documents/10617/Project/cnn-midway.ipynb#X11sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimg_npy \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(img_npy)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arthurjakobsson/Documents/10617/Project/cnn-midway.ipynb#X11sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_dir \u001b[39m=\u001b[39m data_list\n",
      "\u001b[0;31mNameError\u001b[0m: name 'img_npy' is not defined"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "class ImageDataLoader(Dataset):\n",
    "    \"\"\"Quick Draw and Image dataset.\"\"\"\n",
    "\n",
    "    def parseSimplifiedDrawings(fileName):\n",
    "        drawings = []\n",
    "        with open(fileName, 'r') as fileStream:\n",
    "            for obj in ndjson.load(fileStream):\n",
    "                drawings.append(obj)\n",
    "        return drawings\n",
    "\n",
    "    def __init__(self, len, img_dir=\"images\", data_dir=\"data\"):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            len: length of data requested\n",
    "            img_dir (string): path to images\n",
    "            data_dir (string): Directory with all the images.\n",
    "        \"\"\"\n",
    "        self.len = len\n",
    "        self.absolute_path = \"/Users/arthurjakobsson/Documents/10617/Project/\"\n",
    "        img_path = os.path.join(self.absolute_path, img_dir)\n",
    "        data_path = os.path.join(self.absolute_path, data_dir)\n",
    "        img_list = os.listdir(img_path)\n",
    "        data_list = os.listdir(data_dir)\n",
    "        self.img_npy = [np.moveaxis(np.load(os.path.join(img_path, fname)),0,1).flatten() for fname in img_list]\n",
    "        print(self.img_npy[0].shape,self.img_npy[2].shape)\n",
    "        self.img_npy = np.array(img_npy)\n",
    "        self.data_dir = data_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        drawings = parseSimplifiedDrawings(\"data/fence.ndjson\")\n",
    "        #for d in drawings:\n",
    "            #print(d['key_id'], d['countrycode'])\n",
    "        print(\"# of drawings:\", len(drawings))\n",
    "\n",
    "        # img_name = os.path.join(self.root_dir,\n",
    "        #                         self.landmarks_frame.iloc[idx, 0])\n",
    "        # image = io.imread(img_name)\n",
    "        # landmarks = self.landmarks_frame.iloc[idx, 1:]\n",
    "        # landmarks = np.array([landmarks], dtype=float).reshape(-1, 2)\n",
    "        # sample = {'image': image, 'landmarks': landmarks}\n",
    "\n",
    "        # if self.transform:\n",
    "        #     sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "\n",
    "dataloader = ImageDataLoader(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe96a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "batch_size = 32\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "class OurCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=(3,3), stride=1, padding=1)\n",
    "        self.act1 = nn.LogSoftmax(dim=1)\n",
    "        self.drop1 = nn.Dropout(0.3)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=(3,3), stride=1, padding=1)\n",
    "        self.act2 = nn.LogSoftmax(dim=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "\n",
    "        self.flat = nn.Flatten()\n",
    "\n",
    "        self.fc3 = nn.Linear(8192, 512)\n",
    "        self.act3 = nn.LogSoftmax(dim=1)\n",
    "        self.drop3 = nn.Dropout(0.5)\n",
    "\n",
    "        self.fc4 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input 3x32x32, output 32x32x32\n",
    "        x = self.act1(self.conv1(x))\n",
    "        x = self.drop1(x)\n",
    "        # input 32x32x32, output 32x32x32\n",
    "        x = self.act2(self.conv2(x))\n",
    "        # input 32x32x32, output 32x16x16\n",
    "        x = self.pool2(x)\n",
    "        # input 32x16x16, output 8192\n",
    "        x = self.flat(x)\n",
    "        # input 8192, output 512\n",
    "        x = self.act3(self.fc3(x))\n",
    "        x = self.drop3(x)\n",
    "        # input 512, output 10\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "model = OurCNN()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "n_epochs = 20\n",
    "for epoch in range(n_epochs):\n",
    "    for inputs, labels in trainloader:\n",
    "        # forward, backward, and then weight update\n",
    "        y_pred = model(inputs)\n",
    "        loss = loss_fn(y_pred, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    acc = 0\n",
    "    count = 0\n",
    "    for inputs, labels in testloader:\n",
    "        y_pred = model(inputs)\n",
    "        acc += (torch.argmax(y_pred, 1) == labels).float().sum()\n",
    "        count += len(labels)\n",
    "    acc /= count\n",
    "    print(\"Epoch %d: model accuracy %.2f%%\" % (epoch, acc*100))\n",
    "\n",
    "torch.save(model.state_dict(), \"cifar10model.pth\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
